import json
import logging
from enum import Enum
from itertools import zip_longest
from typing import Any, Optional
from uuid import UUID

import aioredis
from aioredis import Redis
from sqlalchemy.ext.declarative import declarative_base

from app.core.config import settings

Base = declarative_base()

REDIS_KEY_DEFAULT_TIMEOUT_IN_SECONDS = 300


def batcher(iterable, n):
    """
    iterate a list in batches of size n
    """
    args = [iter(iterable)] * n
    return zip_longest(*args)


class RedisCache:
    redis: Optional[Redis] = None

    @classmethod
    async def initialize(cls):
        cache: RedisCache = RedisCache()
        await cache.__initialize_cache()
        return cache

    async def __initialize_cache(self):
        if not self.redis:
            logging.info("Initializing cache")
            try:
                self.redis = await aioredis.from_url(settings.REDIS_URI,
                                                     decode_responses=True,
                                                     max_connections=settings.REDIS_MAX_CONNECTION)
            except Exception as e:
                logging.warning(f"Exception occurred while initialising redis {str(e)}")
        if not self.redis:
            logging.error("Could not initialize cache")

    async def delete_cache(self, key_pattern: str):
        if not self.redis:
            await self.__initialize_cache()

        if self.redis:
            try:
                # check if wild card is not present in the key_pattern, then it means single key is being deleted
                if key_pattern.find("*") == -1:
                    await self.redis.delete(key_pattern)
                else:
                    for key_batch in batcher(self.redis.scan_iter(key_pattern), 500):
                        await self.redis.delete(*key_batch)
            except ConnectionError as e:
                self.redis = None
                logging.warning(f"Connect exception occurred while deleting key_pattern {key_pattern} {e}")
            except TimeoutError as e:
                self.redis = None
                logging.warning(f"Timeout exception occurred while deleting key_pattern {key_pattern} {e}")
            except Exception as e:
                self.redis = None
                logging.warning(f"Exception occurred while deleting key_pattern {key_pattern} {e}")

    async def set_cache(self, data: Any, key: str, expiry_in_seconds: int):
        if not self.redis:
            await self.__initialize_cache()

        if self.redis:
            try:
                await self.redis.set(key, json.dumps(data), ex=expiry_in_seconds)
            except ConnectionError as e:
                self.redis = None
                logging.warning(f"Connect exception occurred while calling setting data for key {key} {e}")
            except TimeoutError as e:
                self.redis = None
                logging.warning(f"Timeout exception occurred while calling setting data for key {key} {e}")
            except Exception as e:
                self.redis = None
                logging.warning(f"Exception occurred while calling setting data for key {key} {e}")

    async def get_cache(self, key: str):
        if not self.redis:
            await self.__initialize_cache()

        if self.redis:
            data = None
            try:
                data = await self.redis.get(key)
            except ConnectionError as e:
                self.redis = None
                logging.warning(f"Connect exception occurred while calling fetching data for key {key} {e}")
            except TimeoutError as e:
                self.redis = None
                logging.warning(f"Timeout exception occurred while calling fetching data for key {key} {e}")
            except Exception as e:
                self.redis = None
                logging.warning(f"Exception occurred while calling fetching data for key {key} {e}")

            if data:
                return json.loads(data)
            else:
                logging.info(f"Cache missed for key {key}")

    async def delete_keys(self, key_pattern: str):
        if not self.redis:
            await self.__initialize_cache()

        if self.redis:
            await self.delete_cache(key_pattern=key_pattern)

    @staticmethod
    def get_entity_cache_keys(key: str, *args, **kwargs) -> dict:
        """
        Key for cache is generated by this method
        - Key creation formula used is table name followed by parameter values separated by ":"
        - For example key is to be generated in user, it'll be of the form
          "user:dfe5c762-10b2-44fd-b3f2-2c6387690da8" where "dfe5c762-10b2-44fd-b3f2-2c6387690da8" is the id
          passed in parameter
        """
        logging.debug(f"Key is {key} args is {args} and kwargs is {kwargs}")

        ret: dict = dict()
        if len(args) == 0:
            logging.warning("args length is 0")
            return ret

        for arg in args[0]:
            in_key: str = key
            timeout: int = REDIS_KEY_DEFAULT_TIMEOUT_IN_SECONDS
            if type(arg) is tuple:
                for s in arg:
                    if type(s) is int:
                        timeout = s
                    elif type(s) is str:
                        if s in kwargs:
                            in_key = f'{in_key}:{str(kwargs[s])}'
                        else:
                            logging.warning(f"Could not find {s} in kwargs {kwargs}")
                            in_key = key
                            break
                    else:
                        logging.warning(f"Unsupported data type in key generation")
                        in_key = key
                        break
                if in_key != key:
                    ret[in_key] = timeout
            else:
                logging.warning(f"Unsupported data type in key generation")

        logging.debug(f"Generated keys from _get_entity_cache_key is {ret}")
        return ret

    @staticmethod
    def to_dict(data: Base):
        return \
            {c.name: bool(getattr(data, c.name))
            if isinstance(getattr(data, c.name), bool)
            else int(getattr(data, c.name))
            if isinstance(getattr(data, c.name), int)
            else getattr(data, c.name).value
            if isinstance(getattr(data, c.name), Enum)
            else getattr(data, c.name)
            if getattr(data, c.name) in [None]
            else str(getattr(data, c.name))
             for c in data.__table__.columns}


redis_cache: RedisCache


async def initialize_cache():
    global redis_cache
    redis_cache = await RedisCache.initialize()


class GetCachedEntity(object):
    """Strictly to be used for read only. It does not return an orm object, it just returns a json"""

    def __init__(self, *args, **kwargs):
        super(GetCachedEntity, self).__init__()
        self.args = args
        self.kwargs = kwargs

    def __call__(self, fn):
        async def execute_method(*args, **kwargs):
            generated_keys: dict = dict()
            if len(args) > 0:
                generated_keys = redis_cache.get_entity_cache_keys(args[0].model.__tablename__, self.args, **kwargs)
                for key in generated_keys:
                    data = await redis_cache.get_cache(key)
                    if data:
                        logging.debug(f"Data extracted from cache for key {key}")
                        data = args[0].model(**data)
                        try:
                            data.id = UUID(data.id)
                        except (ValueError, AttributeError) as e:
                            pass
                        except Exception as e:
                            logging.warning(f"Exception for id conversion to uuid {e}")
                        return data

            to_execute: Base = await fn(*args, **kwargs)
            if to_execute:
                for key in generated_keys:
                    # If the data to be cached is of type uuid or any other type which
                    # cannot be stored in json will be converted to string and hence make sure while using the data
                    # string case is handled or converted to required class ot type
                    await redis_cache.set_cache(redis_cache.to_dict(data=to_execute), key=key,
                                                expiry_in_seconds=generated_keys[key])

            return to_execute

        return execute_method


class SetCacheEntity(object):
    """Strictly to be used for read only. It does not return an orm object, it just returns a json"""

    def __init__(self, *args, **kwargs):
        super(SetCacheEntity, self).__init__()
        self.args = args
        self.kwargs = kwargs

    def __call__(self, fn):
        async def execute_method(*args, **kwargs):
            to_execute: Base = await fn(*args, **kwargs)
            if to_execute:
                data = redis_cache.to_dict(data=to_execute)
                generated_keys: dict = redis_cache.get_entity_cache_keys(args[0].model.__tablename__,
                                                                         self.args, **data)
                for key in generated_keys:
                    await redis_cache.set_cache(data=redis_cache.to_dict(data=to_execute),
                                                key=key, expiry_in_seconds=generated_keys[key])
            return to_execute

        return execute_method
